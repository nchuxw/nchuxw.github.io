---
title: 'CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs'
date: 2021-04-28
categories: 论文解读
tags: [arm, 嵌入式, 神经网络, 深度学习]
mathjax: true
---

[论文原文下载链接](https://cdn.jsdelivr.net/gh/stxw/stxw.github.io/documnets/papers/CMSIS-NN.pdf)

# 摘要

&emsp;&emsp;深度神经网络在始终在线的IoT外围设备中变得越来越流行，这些IoT外围设备从源头开始执行数据分析，从而减少了数据通信的延迟和能耗。本文介绍了CMSIS-NN，这些高效的内核经过开发，可在针对智能IoT外围设备的Arm Cortex-M处理器上最大化性能并最小化神经网络（NN）应用程序的内存占用量。基于CMSIS-NN内核的神经网络推理可将运行时间/吞吐量提高4.6倍，将能效提高4.9倍。


# 介绍

&emsp;&emsp;过去几年中，互联设备（也称为物联网（IoT））迅速增长，预计到2035年在各个市场领域将达到1万亿[1]。这些IoT外围设备通常由收集数据（例如音频，视频，温度，湿度，GPS位置和加速度）的传感器组成，然后进行处理并与其他节点或云进行通信。当前，来自传感器的数据由云中的分析工具进行处理，以实现广泛的应用，例如工业监控，家庭自动化和医疗保健。但是，随着IoT节点数量的增加，这给网络带宽带来了相当大的负担，并给IoT应用程序增加了延迟。此外，对云的依赖使在网络连接受限或不可靠的区域中部署物联网应用程序带来了挑战。解决此问题的一种解决方案是外围计算[2]，它直接在数据源即IoT外围节点上执行，从而减少了等待时间并节省了数据通信的功耗。

&emsp;&emsp;在准确性方面，深度神经网络已经证明了在许多复杂的机器学习应用程序中的有接近人的表现，例如图像分类，语音识别和自然语言处理。一个典型的用于图像分类的神经网络（NN）由多层基于卷积的特征提取器组成，然后是用于分类的全连接层，如图1所示。由于计算复杂性和资源需求，神经网络的执行主要限于使用高性能服务器CPU或专用硬件（例如GPU或加速器）进行的云计算，这会增加IoT应用程序的延迟。在数据源即IoT外围处使用小型神经网络进行分类可以减少IoT外设与云之间的数据通信的总体延迟和能耗。

&emsp;&emsp;在这项工作中，我们探索了基于资源受限的微控制器平台上神经网络的性能优化，该平台针对智能物联网外围节点。为此，我们开发了优化的软件内核，用于在Arm Cortex-M CPU上部署NN。使用这些软件内核，我们在现成的Arm Cortex-M7平台上演示了针对CIFAR-10数据集的卷积神经网络（CNN），该算法每秒可分类10.1张图像，准确度为79.9％。


# 概述

&emsp;&emsp;神经网络内核的概述如图2所示。内核代码由两部分组成：`NNFunctions`和`NNSupportFunctions`。`NNFunctions`包含了流行的神经网络层类型的函数实现，例如卷积，深度可分离卷积，全连接（即内积），池化和激活。应用程序代码可以使用这些函数来实现神经网络推理应用程序。内核API也保持简单，因此可以轻松地将它们移植到任何机器学习框架。`NNSupportFunctions`包括实用程序功能，例如`NNFunctions`中使用的数据转换和激活函数表。应用程序代码还可使用这些实用程序功能来构建更复杂的NN模块，例如长短期记忆（LSTM）或门控循环单元（GRU）。

&emsp;&emsp;对于某些内核，例如全连接和卷积，将实现不同版本的内核函数。提供了一个基本版本，可以对所有层参数普遍使用“原样”。我们还实现了其他版本，其中包括进一步的优化技术，这些技术要么具有转换后的输入，要么对层参数有一些限制。理想情况下，可以使用简单的脚本来解析网络拓扑并自动确定要使用的适当功能。


# 定点量化

&emsp;&emsp;传统上，使用32位浮点数据表示来训练NN模型。但是，推理期间通常不需要这种高精度。研究表明，即使使用低精度定点表示，神经网络也能很好地运行。定点量化有助于避免昂贵的浮点计算，并减少用于存储权重和激活的内存占用，这对于资源受限的平台至关重要。

&emsp;&emsp;尽管不同网络或网络层的精度要求可能会有所不同，但CPU很难对位宽不同的数据类型进行操作。在这项工作中，我们开发了支持8位和16位数据的内核。内核采用与CMSIS中相同的数据类型格式，即$q7\_t$作为$int8$，$q15\_t$作为$int16$，$q31\_t$作为$int32$。假定以2的幂进行定点格式量化，即表示的值将为$A \times 2^n$，其中$A$为整数值，$n$表示小数点位置的整数。我们将偏置的缩放因子传递给内核，并将其作为参数传递给内核，并且由于二次幂缩放，缩放可以用按位移位运算实现。我们使用这种类型的量化（而不是TensorFlow中使用的8位量化）来避免在层之间进行浮点反量化，因为某些Arm Cortex-M CPU可能没有专用的浮点单元（FPU），从而限制了它们的浮点计算能力。这种量化的另一个好处是我们可以使用更简单的基于表查找的激活，这将在第4.5节中讨论。


# 软件内核

&emsp;&emsp;在本节中，我们描述了提出的软件内核的实现和优化，用于Arm Cortex-M CPU。Cortex-M 系列处理器是32位RISC处理器内核，旨在提高能效，通常用作深度嵌入式应用的微控制器。在这项工作中，我们专注于在支持SIMD指令且基于Cortex-M的系统上启用神经网络，尤其是对NN计算非常有用的16位乘法和累加（MAC）指令（例如SMLAD）。

## Support Functions

&emsp;&emsp;大多数NNFunction使用16位MAC指令，因此需要数据转换才能将8位数据类型（即$q7\_t$）转换为16位数据类型（即$q15\_t$）。CMSIS提供了一个实用程序函数$arm_q7_to_q15$来执行数据转换。图示和伪代码如图3所示。数据转换分为两个步骤：第一步，使用符号扩展指令（__SXTB16）将8位数据扩展为16位数据。第二步重新排列数据，以便输出遵循与输入相同的顺序。



